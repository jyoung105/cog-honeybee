#!/usr/bin/env python

# Run this before you deploy it on replicate
import os
import sys
import torch
import subprocess
from honeybee.pipeline.interface import get_model


# Append project directory to path so predict.py can be imported
sys.path.append('.')
from predict import MODEL_CACHE, MODEL_URL

# Make cache folders
if not os.path.exists(MODEL_CACHE):
    os.makedirs(MODEL_CACHE)
    
subprocess.check_call(["pget", MODEL_URL, MODEL_CACHE], close_fds=False)
subprocess.check_call(["tar", "-zxvf", MODEL_CACHE])

ckpt_path = "checkpoints/7B-C-Abs-M256/last"

model, tokenizer, processor = get_model(ckpt_path, use_bf16=True)
model.cuda()
model.save_pretrained(MODEL_CACHE)